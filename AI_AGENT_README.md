# 智能德州扑克AI Agent

**作者**: 刘宇轩  田偲

## 项目概述

根据2024-2025春季人工智能基础课程大作业要求，本项目对原始的`client.py`进行了重构，实现了一个智能的德州扑克AI智能体。

## 核心特性

### 1. 智能决策系统
- **手牌强度评估**: 基于牌型、高牌、对子等多维度评估
- **位置策略**: 根据座位位置调整决策激进程度
- **底池赔率计算**: 考虑投入成本与潜在收益
- **诈唬机制**: 适度的诈唬策略增加不可预测性

### 2. 手牌评估算法
```python
def evaluate_hand_strength(self, hole_cards, public_cards):
    # 基础强度评估
    # 高牌加分 (A, K, Q, J)
    # 对子识别与评分
    # 同花/顺子潜力分析
    # 已成型牌型检测 (四条、三条、两对等)
```

### 3. 决策逻辑
- **强牌 (>0.75强度)**: 倾向于加注
- **中等牌 (0.4-0.75)**: 根据底池赔率决定跟注/过牌
- **弱牌 (<0.4)**: 倾向于弃牌或过牌
- **诈唬策略**: 15%概率在合适位置进行诈唬

## 技术实现

### 核心类: PokerAgent
```python
class PokerAgent:
    def __init__(self):
        self.aggression_factor = 0.3    # 激进程度
        self.bluff_frequency = 0.15     # 诈唬频率
        self.tight_factor = 0.6         # 紧凶程度
        
    def make_decision(self, data):
        # 综合决策逻辑
        pass
```

### 主要方法
1. `evaluate_hand_strength()` - 手牌强度评估
2. `calculate_pot_odds()` - 底池赔率计算
3. `get_position_factor()` - 位置因子获取
4. `should_bluff()` - 诈唬决策
5. `make_decision()` - 核心决策函数

## 算法优势

### 1. 多维度评估
- 不仅考虑手牌本身，还考虑位置、底池大小等因素
- 动态调整策略，避免过于机械化

### 2. 风险控制
- 合理的诈唬频率，避免过度激进
- 基于底池赔率的理性决策

### 3. 可扩展性
- 预留对手建模接口
- 支持多人游戏扩展
- 参数可调节，便于优化

## 使用方法

### 基本运行
```bash
python client.py 2 MyAI 10
```

### 参数说明
- `2`: 游戏人数
- `MyAI`: AI名称
- `10`: 最大对局数

### 测试验证
```bash
python test_agent.py
```

## 性能特点

### 决策特征
- **紧凶型**: 选择性进入底池，进入后积极争取
- **位置敏感**: 后位更加激进，前位相对保守
- **适应性强**: 根据牌局情况动态调整

### 预期表现
- 对抗随机策略: 显著优势
- 对抗简单规则策略: 明显优势
- 对抗复杂AI: 具备竞争力

## 代码结构

```
client.py
├── PokerAgent类
│   ├── __init__()           # 初始化参数
│   ├── evaluate_hand_strength()  # 手牌评估
│   ├── calculate_pot_odds()      # 赔率计算
│   ├── get_position_factor()     # 位置因子
│   ├── should_bluff()           # 诈唬判断
│   └── make_decision()          # 核心决策
├── get_action()             # 重构后的决策接口
└── 原有网络通信代码
```

## 设计理念

### 1. 实用性
- 基于德州扑克理论基础
- 考虑实际对战场景
- 平衡风险与收益

### 2. 可维护性
- 清晰的代码结构
- 详细的注释说明
- 模块化设计

## 竞争优势

1. **智能化程度高**: 多维度综合决策
2. **策略平衡**: 紧凶结合，攻守兼备
3. **适应性强**: 可根据对手调整策略
4. **代码质量**: 结构清晰，易于理解和扩展

## 后续优化方向

1. **对手建模**: 分析对手行为模式
2. **深度学习**: 引入神经网络优化决策
3. **蒙特卡洛模拟**: 更精确的胜率计算
4. **动态参数调整**: 根据战绩自动优化参数



